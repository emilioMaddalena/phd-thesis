\appendix

\chapter{Elements of analysis and geometry}
\label{app.elements_analysis_algebra}

For a comprehensive presentation of the concepts, the reader os referred to \cite{searcoid2002elements,pugh2002real}. 

All vector spaces herein are defined over the field of real numbers $\mathbb{R}$.

\begin{definition}
	\textbf{(Metric space)}
	A metric space is a vector space $(V,+,\times)$ equipped with a map $d(\cdot,\cdot):V \times V \rightarrow \mathbb{R}$ called a \textit{metric} satisfying
	\begin{align}
		(i) \, &d(v,v) \geq 0 \\
		(ii) \, &d(v,w) = 0 \Leftrightarrow v = w\\
		(iii) \, &d(v,w) = d(w,v) \\
		(iv) \, &d(v,w) \leq d(v,z) + d(z,w)
	\end{align}
	for any $v,w,z \in V$.
\end{definition}

For simplicity, we write $(V,d)$ instead of $(V,+,\times,d)$.

\begin{definition}
	\textbf{(Convergent sequence)}
	Given a metric space $(X,d)$, a sequence $\{x_n\}_{n\in\mathbb{N}}$ in $X$ is said to \textit{converge} to an element $x \in X$ if
	\begin{equation}
		\forall \epsilon > 0 \, : \, \exists N \in \mathbb{N} \, : \,  \forall n \geq N \, : \, d(x_n, x) < \epsilon
	\end{equation}
\end{definition}

Convergent sequences are usually written $\lim_{n \rightarrow \infty} x_n = x$ or more simply $x_n \rightarrow x$. Moreover, sequences cannot converge to two or more points.

\begin{definition}
	\textbf{(Cauchy sequence)}
	Given a metric space $(X,d)$, a sequence $\{x_n\}_{n\in\mathbb{N}}$ in $X$ is said to be \textit{Cauchy} if
	\begin{equation}
		\forall \epsilon > 0 \, : \, \exists N \in \mathbb{N} \, : \,  \forall n,m \geq N \, : \, d(x_n, x_m) < \epsilon
	\end{equation}
\end{definition}

Cauchy sequences are a superset of convergent sequences.

\begin{definition}
	\textbf{(Complete space)}
	A metric space is $(V,+,\times,d)$ is said to be complete if every Cauchy sequence $\{x_n\}_{n\in\mathbb{N}}$ converges to an element $x \in X$.
\end{definition}


\begin{definition}
	\textbf{(Normed space)}
	A normed space is a vector space $(V,+,\times)$ equipped with a map $\Vert \cdot \Vert: V \rightarrow \mathbb{R}$ called a \textit{norm} satisfying
	\begin{align}
	(i) \, &\Vert v \Vert \geq 0 \\
	(ii) \, &\Vert v \Vert = 0 \Leftrightarrow v = 0\\
	(iii) \, &\Vert \alpha v \Vert = |\alpha| \, \Vert v \Vert \\
	(iv) \, &\Vert  v + w \Vert \leq \Vert v \Vert + \Vert w \Vert
	\end{align}
	for any $v,w \in V$ and any $\alpha \in \mathbb{R}$.
\end{definition}

Metrics can be defined via norms through $d(x,y) := \Vert x - y\Vert$. As a result, every normed space is a metric space.

\begin{definition}
	\textbf{(Banach space)}
	A normed space $(X,\Vert \cdot \Vert)$ is called a Banach space if it is complete.
\end{definition}

\begin{definition}
	\textbf{(Inner-product space)}
	An inner-product space is a vector space $(X,+,\times)$ equipped with a map $\langle \cdot, \cdot \rangle : X \times X \rightarrow \mathbb{R}$ called an \textit{inner-product} satisfying
	\begin{align}
		(i) \, &\langle x, y \rangle = \langle y, x \rangle\\
		(ii) \, &\langle \alpha x + \beta y, z \rangle = \alpha \langle x, z \rangle + \beta \langle y, z \rangle\\
		(iii) \, &\langle x, x \rangle \geq 0 \\
		(iv) \, &\langle x, x \rangle = 0 \Leftrightarrow x = 0
	\end{align}
	for any $v,w \in V$ and any $\alpha \in \mathbb{R}$.
\end{definition}

Norms can be defined via inner-products through $\Vert x \Vert := \sqrt{\langle x, x\rangle}$. As a result, every inner-product space is also a normed space.

\begin{definition}
	\textbf{(Hilbert space)}
	An inner-product space $(X,\langle \cdot, \cdot \rangle)$ is called a Hilbert space if it is complete.
\end{definition}

\begin{definition}
	\textbf{(Bounded linear operator)}
	Let $(V, \Vert \cdot \Vert_V)$ and $(W, \Vert \cdot \Vert_W)$ be two Banach spaces. A map $A:V \mapsto W$ is said to be a bounded linear operator if
	\begin{equation}
		\sup_{v \in V \backslash \{0\}} \frac{ \Vert Av \Vert_W }{ \Vert v \Vert_V } < \infty
	\end{equation}
\end{definition}

\begin{definition}
	\label{def.operator_norm}
	\textbf{(Operator norm)}
	Let $A:V \mapsto W$ be a bounded linear operator. The operator norm is defined as
	\begin{equation}
		\Vert A \Vert := \sup_{v \in V \backslash \{0\}} \frac{ \Vert Av \Vert_W }{ \Vert v \Vert_V } 
	\end{equation}
\end{definition}

\begin{definition}
	\textbf{(Pointwise convergence)}
	Let $X, Y$ be two metric spaces and $\{f_n\}_{n\in\mathbb{N}}$ be a sequence of functions where $f_n : X \rightarrow Y$ for all $n$. The sequence is said to converge to a function $f: X \rightarrow Y$ if for every $x \in X$
	\begin{equation}
		\lim_{n \rightarrow \infty} f_n(x) = f(x)
	\end{equation}
\end{definition}

The example below, taken from \cite[ยง1]{berlinet2011reproducing}, highlights an issue one has to pay attention to when working with spaces of functions.

\begin{example}
	\label{ex.appendix_convergence}
	\textbf{(Convergence does not imply pointwise convergence)}
	Let $P$ be the vector space of all polynomials over $[0,1]$ and endow it with the norm
	\begin{equation}
		\Vert f \Vert_{P} = \left( \int_{0}^{1} |f(x)|^2 \text{d}x \right)^{1/2}
	\end{equation}
	The sequence $\{p_n\}_{n\in\mathbb{N}}, \, p_n(x) = x^n$ converges to the zero function since
	\begin{align}
		\lim_{n \rightarrow \infty} \Vert p_n - 0\Vert_{P} &= \lim_{n \rightarrow \infty} \left( \int_{0}^{1} x^{2n} \text{d}x \right)^{1/2} \\
		&= \lim_{n \rightarrow \infty} \frac{1}{\sqrt{2n+1}} \\
		&= 0
	\end{align}
	and yet $p_n(1) = 1, \forall n$, i.e., $|p_n(x) - 0(x)| \nrightarrow 0$.
\end{example}

\begin{definition}
	\textbf{(Span)}
	Let $X$ be a vector space and $B \subseteq X$ be a subset of it. The \textit{span} of $B$ is defined as the set
	\begin{equation}
		\text{span}\,B = \left\{ \sum_{i=1}^n \lambda_i b_i \, | \, \lambda_i \in \mathbb{R}, b_i \in B, n \in \mathbb{N} \right\} 
	\end{equation}
\end{definition}

\begin{definition}
	\textbf{(Linear independence)}
	Let $X$ be a vector space and $B \subseteq X$ be a subset of it. $B$ is said to be linearly independent if for every finite subset $\{b\}_{i=1}^n \subseteq B$, $\sum_{i=1}^n \lambda_i b_i = 0 \iff \lambda_1=\dots=\lambda_n = 0$.
\end{definition}

\begin{definition}
	\textbf{(Hamel basis)}
	Let $X$ be a vector space and $B \subseteq X$. $B$ is called a Hamel basis for $X$ if $B$ is linearly independent and $\text{span}\,B = X$.
\end{definition}

\begin{proposition}
	Every vector space has a Hamel basis.
	% \cite[Theorem~3.2.9]{searcoid2002elements}
\end{proposition}

\begin{proposition}
	All Hamel bases of a vector space have the same cardinality.
	% \cite[Theorem~3.2.13]{searcoid2002elements}
\end{proposition}

The concept of a Hamel basis is aligned with the more specific concept of a ``basis'' in finite-dimensional vector spaces. 

\begin{definition}
	\textbf{(Dimension of a vector space)}
	The dimension of a vector space denoted $\text{dim}\,X$ is the cardinality of any Hamel basis $B$ of $X$. If any $B$ is not finite, $X$ is said to be infinite-dimensional.
\end{definition}

\begin{proposition}
	Let $A \in \mathbb{R}^{d\times d}$ be an invertible matrix, $B \in \mathbb{R}^d$ and $c \in \mathbb{R}$. The following identity holds
	\begin{equation}
		\label{eq.matrix_inv_lemma}
		\begin{bmatrix}
			A & B \\
			B^\top & c
		\end{bmatrix}^{-1} 
		= 	\begin{bmatrix}
			A^{-1} + \frac{1}{d}A^{-1}BB^\top A^{-1} & - \frac{1}{d}A^{-1}B \\[3pt]
			- \frac{1}{d}B^\top A^{-1} & \frac{1}{d}
		\end{bmatrix}
	\end{equation}
	where $d = c - B^\top A^{-1} B$.
\end{proposition}

\begin{definition}
	\textbf{(Polyhedron)}
	A polyhedron $P \subseteq \mathbb{R}^n$ is a set $P = \{x \in \mathbb{R}^n : p_i(x) \leq 0, i=1,\dots,n_P\}$ with $n_P < \infty$ and $p_i(x)$ being are affine functions.
\end{definition}

\begin{definition}
	\textbf{(Polytope)}
	A polytope $P \subset \mathbb{R}^n$ is a bounded polyhedron.
\end{definition}

\begin{definition}
	\textbf{(Polyhedral projection)}
	Let $P \subset \mathbb{R}^n$ be a polyhedron described by $\{x \in \mathbb{R}^n \, | \, H x \leq h \}$ for some $H \in \mathbb{R}^{n \times m}$ and $h \in \mathbb{R}^{m}$. The projection of a point $z \in \mathbb{R}^n$ onto $P$ is defined as the vector $p^\star \in \mathbb{R}^n$
	\begin{align}
		\label{def.pol_proj}
		p^\star = \argmin_{p \in \mathbb{R}^n} \ &\Vert p - z \Vert_2^2 \\
		\text{subj. to} \ & H p \leq h \nonumber
	\end{align}
	and it is usually denoted as $\text{Proj}_P(x)$.
\end{definition}

%\mycomment{Perhaps explain the difference between SUP and MAX, INF and MIN. }


%
%\chapter{Properties of kernels}
%
%Let $k$, $k_1$ and $k_2$ be PD kernels (Definition~\ref{def.pd_kernel}) defined on $\Omega \times \Omega$, $\Omega \subseteq \mathbb{R}^n$. Let $\alpha \geq 0$ be an arbitrary positive scalar. We have that the new function $k^\star$ as defined by any of the following constructions is also a PD kernel
%\begin{align}
%	& k^\star(x,x') := \alpha k(x,x') \\
%	& k^\star(x,x') := k_1(x,x') + k_2(x,x') \\
%	& k^\star(x,x') := k_1(x,x') k_2(x,x') 
%\end{align}
%
%\begin{my_proof}
%	For the first three cases, see \cite[ยง4]{steinwart2008svm_book}.
%\end{my_proof}
%
